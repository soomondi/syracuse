{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROCESSING AND CLASSIFICATION OF THE KAGGLE MOVIE REVIEW DATA\n",
    "\n",
    "\n",
    "**IST 664 FINAL PROJECT**\n",
    "\n",
    "**STEPHEN OMONDI**\n",
    "\n",
    "**June 15, 2020**\n",
    "\n",
    "**Course Instructor: Professor Paloma**\n",
    "\n",
    "_____________________________________________________________________________________\n",
    "\n",
    "\n",
    "### INTRODUCTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kaggle Movie Review Data was taken from the original Pang and Lee movie review corpus based on reviews from the Rotten Tomatoes web site. Socher’s group used crowd-sourcing to manually annotate all the subphrases of sentences with a sentiment label that went into this movie review library.\n",
    "\n",
    "**The sentiment labels used were:**\n",
    "\n",
    "0 - negative\n",
    "\n",
    "1 - slightly negative \n",
    "\n",
    "2 - neutral \n",
    "\n",
    "3 - slightly positive \n",
    "\n",
    "4 – positive\n",
    "\n",
    "This analysis uses the training data “train.tsv”, and test data “test.tsv”. The training data file has 156,060 phrases, and the early part of the analysis chooses an appropriate subset for processing and training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this analysis is to predict the sentiments of each review using algorithmic approach and make a comparison of results by tweaking underlying parameters such as the effect on the classification based on different filtering and preprocessing approaches. Finally, a summary comparison of different algorithmic classifiers, such as Naïve Bayes classification, Random Forests, Decision Trees and more from the Sci-Kit Learn ecosystem are compared along common measures of prediction accuracy to determine the winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Fetching data from train.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, begin by reading the training tab separated values file. The file has 156,060 phrases. random phrases were selected to avoid overlaps and to display a wider segment of the total phrases some of which are shown below, along with their sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read kaggle training file, train and test a classifier \n",
    "def processkaggle(dirPath,limitStr):\n",
    "  # convert the limit argument from a string to an int\n",
    "  limit = int(limitStr)\n",
    "  \n",
    "  os.chdir(dirPath)\n",
    "  \n",
    "  f = open('corpus/train.tsv', 'r')\n",
    "  # loop over lines in the file and use the first limit of them\n",
    "  phrasedata = []\n",
    "  for line in f:\n",
    "    # ignore the first line starting with Phrase and read all lines\n",
    "    if (not line.startswith('Phrase')):\n",
    "      # remove final end of line character\n",
    "      line = line.strip()\n",
    "      # each line has 4 items separated by tabs\n",
    "      # ignore the phrase and sentence ids, and keep the phrase and sentiment\n",
    "      phrasedata.append(line.split('\\t')[2:4])\n",
    "    \n",
    "  # pick a random sample of length limit because of phrase overlapping sequences\n",
    "  random.shuffle(phrasedata)\n",
    "  phraselist = phrasedata[:limit]\n",
    "\n",
    "  print('Read', len(phrasedata), 'phrases, using', len(phraselist), 'random phrases')\n",
    "  \n",
    "  for phrase in phraselist[:10]:\n",
    "    return phraselist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 156060 phrases, using 3000 random phrases\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['from its cheesy screenplay', '1'],\n",
       " ['seen -LRB- Eddie -RRB-', '3'],\n",
       " ['play off each other virtually to a stand-off ,', '1'],\n",
       " ['colour and', '2'],\n",
       " [\"Like a soft drink that 's been sitting open too long : it 's too much syrup and not enough fizz .\",\n",
       "  '0'],\n",
       " ['jolts the laughs from the audience --', '3'],\n",
       " [\"at least during their '70s\", '2'],\n",
       " ['Too campy to work as straight drama', '1'],\n",
       " ['a more credible script ,', '3'],\n",
       " ['some other recent efforts', '2']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the path where the kaggles review dataset is located\n",
    "dirPath = \"C:\\\\Academics\\\\Natural Language Processing\\\\Final Project\\\\FinalProjectData\\\\FinalProjectData\\\\kagglemoviereviews\"\n",
    "\n",
    "# now call the processing function, call 3000 random records\n",
    "reviews = processkaggle(dirPath,3000)\n",
    "reviews[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Deciding on an appropriate Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three approaches are explored in order to decide on a best tokenization approach and set the stage for forthcoming experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Sklearn Countvectorize tokenizer**\n",
    "\n",
    "This tokenizer removes all single character words. For example, the word won’t became won and all abbreviated words were removed, e.g. U.K was omitted altogether. This approach may not be ideal when handling negative sentiments or negative words as they are lost in the tokenization which may lead to a different meaning of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['from', 'its', 'cheesy', 'screenplay'], 1),\n",
       " (['seen', 'LRB', 'Eddie', 'RRB'], 3),\n",
       " (['play', 'off', 'each', 'other', 'virtually', 'to', 'stand', 'off'], 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# countvectorize\n",
    "def countvector_token(phraselist):\n",
    "    phrasedocs4 = []\n",
    "    for phrase in phraselist:\n",
    "        cvtokens = CountVectorizer().build_tokenizer()(phrase[0])\n",
    "        phrasedocs4.append((cvtokens, int(phrase[1])))\n",
    "    return phrasedocs4\n",
    "\n",
    "# displaying only the first 3\n",
    "countvector_token(reviews[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- NLTK Word Tokenizer**\n",
    "\n",
    "This approach preserves abbreviated words like U.S.A but splits negative words like *can’t* into two parts, *can* and *‘t*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['from', 'its', 'cheesy', 'screenplay'], 1),\n",
       " (['seen', '-LRB-', 'Eddie', '-RRB-'], 3),\n",
       " (['play', 'off', 'each', 'other', 'virtually', 'to', 'a', 'stand-off', ','],\n",
       "  1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## word tokenizer\n",
    "def word_tokenizer(phraselist):\n",
    "    w_tokens = []\n",
    "    # add all the phrases\n",
    "    for phrase in phraselist:\n",
    "        tokens = nltk.word_tokenize(phrase[0])\n",
    "        w_tokens.append((tokens, int(phrase[1])))\n",
    "    return w_tokens\n",
    "\n",
    "word_tokens = word_tokenizer(reviews)\n",
    "\n",
    "# displaying only the first 3\n",
    "word_tokens[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WordPunct Tokenizer**\n",
    "\n",
    "This tokenizer treats punctuations as words on their own. For example, words like *‘U.S.A.’* becomes six words- *‘U’,’.’,’S’,’.’,’A’,’.’* and *‘ca n’t’* becomes four words- *‘ca’,’n’, ’’’ ,’t’*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['from', 'its', 'cheesy', 'screenplay'], 1),\n",
       " (['seen', '-', 'LRB', '-', 'Eddie', '-', 'RRB', '-'], 3),\n",
       " (['play',\n",
       "   'off',\n",
       "   'each',\n",
       "   'other',\n",
       "   'virtually',\n",
       "   'to',\n",
       "   'a',\n",
       "   'stand',\n",
       "   '-',\n",
       "   'off',\n",
       "   ','],\n",
       "  1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## word_punct tokenizer\n",
    "def word_puncktokens(phraselist):\n",
    "    wp_tokens = []\n",
    "    for phrase in phraselist:\n",
    "        wptokens = nltk.wordpunct_tokenize(phrase[0])\n",
    "        wp_tokens.append((wptokens, int(phrase[1])))\n",
    "    return wp_tokens\n",
    "\n",
    "# displaying only the first 3\n",
    "word_puncktokens(reviews[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the foregoing analyses, *NLTK Wordtokenizer is the preferred method and is used in the subsequent sections.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3 - Processing the Reviews/Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Lowercase**\n",
    "\n",
    "Convert all reviews to lowercase. This is important because NLTK algorithm is case sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('from its cheesy screenplay', '1'),\n",
       " ('seen -lrb- eddie -rrb-', '3'),\n",
       " ('play off each other virtually to a stand-off ,', '1'),\n",
       " ('colour and', '2'),\n",
       " (\"like a soft drink that 's been sitting open too long : it 's too much syrup and not enough fizz .\",\n",
       "  '0'),\n",
       " ('jolts the laughs from the audience --', '3'),\n",
       " (\"at least during their '70s\", '2'),\n",
       " ('too campy to work as straight drama', '1'),\n",
       " ('a more credible script ,', '3'),\n",
       " ('some other recent efforts', '2')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert all characters to lower case\n",
    "def to_lower(phrases):\n",
    "    sents_to_lower= []\n",
    "    for phrase in phrases:\n",
    "        lower_tokens = phrase[0].lower()\n",
    "        sents_to_lower.append((lower_tokens, phrase[1]))\n",
    "    return sents_to_lower\n",
    "\n",
    "all_reviews = to_lower(reviews)\n",
    "\n",
    "# displaying only the first 10\n",
    "all_reviews[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Clean the reviews to include negative / contraction words**\n",
    "\n",
    "Expand the stop words list by removing contraction words like *can't* to *can not*. Thus, this proces extends the stop words with apostrophes. This is important as it helps the word_tokenizer perform better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('from its cheesy screenplay', '1'),\n",
       " ('seen -lrb- eddie -rrb-', '3'),\n",
       " ('play off each other virtually to a stand-off ,', '1'),\n",
       " ('colour and', '2'),\n",
       " ('like a soft drink that is been sitting open too long : it is too much syrup and not enough fizz .',\n",
       "  '0'),\n",
       " ('jolts the laughs from the audience --', '3'),\n",
       " (\"at least during their '70s\", '2'),\n",
       " ('too campy to work as straight drama', '1'),\n",
       " ('a more credible script ,', '3'),\n",
       " ('some other recent efforts', '2')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanextend(phrases):\n",
    "    phrases_without_contractions = []\n",
    "    for review in phrases:\n",
    "        extended_rev = re.sub(r\"it \\'s\", \"it is\", review[0])\n",
    "        extended_rev = re.sub(r\"that 's\", \"that is\", extended_rev)\n",
    "        extended_rev = re.sub(r\"\\'s\", \"\\'s\", extended_rev)\n",
    "        extended_rev = re.sub(r\"\\'ve\", \"have\", extended_rev)\n",
    "        extended_rev = re.sub(r\"wo n't\", \"will not\", extended_rev)\n",
    "        extended_rev = re.sub(r\"do n't\", \"do not\", extended_rev)\n",
    "        extended_rev = re.sub(r\"ca n't\", \"can not\", extended_rev)\n",
    "        extended_rev = re.sub(r\"sha n't\", \"shall not\", extended_rev)\n",
    "        extended_rev = re.sub(r\"n\\'t\", \"not\", extended_rev)\n",
    "        extended_rev = re.sub(r\"\\'re\", \"are\", extended_rev)\n",
    "        extended_rev = re.sub(r\"\\'d\", \"would\", extended_rev)\n",
    "        extended_rev = re.sub(r\"\\'ll\", \"will\", extended_rev)\n",
    "        phrases_without_contractions.append((extended_rev, review[1]))\n",
    "    return phrases_without_contractions\n",
    "\n",
    "all_reviews = cleanextend(all_reviews)\n",
    "\n",
    "# displaying only the first 10\n",
    "all_reviews[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing punctuations, along with numbers**\n",
    "\n",
    "This is necessary since punctuations and numbers will not be necessary for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('from its cheesy screenplay', '1'),\n",
       " ('seen lrb eddie rrb', '3'),\n",
       " ('play off each other virtually to a standoff ', '1'),\n",
       " ('colour and', '2'),\n",
       " ('like a soft drink that is been sitting open too long  it is too much syrup and not enough fizz ',\n",
       "  '0'),\n",
       " ('jolts the laughs from the audience ', '3'),\n",
       " ('at least during their s', '2'),\n",
       " ('too campy to work as straight drama', '1'),\n",
       " ('a more credible script ', '3'),\n",
       " ('some other recent efforts', '2')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuations(phrases):\n",
    "    phrases_without_punctuations = []\n",
    "    for text in phrases:\n",
    "        punctuation = re.compile(r'[-_.?!/\\%@,\":;\\'{}<>~`\\()|0-9]')\n",
    "        word = punctuation.sub(\"\", text[0])\n",
    "        phrases_without_punctuations.append((word, text[1]))\n",
    "    return phrases_without_punctuations\n",
    "\n",
    "all_reviews = remove_punctuations(all_reviews)\n",
    "\n",
    "# displaying only the first 10\n",
    "all_reviews[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Updating the stopwords to include certain negative words**\n",
    "\n",
    "These additional words will be useful in sentiment analysis but do not already exist in the provided stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating the stopwords to include certain negative words which will be useful in sentiment analysis\n",
    "STOPWORDS = nltk.corpus.stopwords.words('english')\n",
    "updatestopwords = [word for word in STOPWORDS if word not in ['not', 'no', 'can','has','have','had','must','shan','do', 'should','was','were','won','are','cannot','does','ain', 'could', 'did', 'is', 'might', 'need', 'would']]\n",
    "clean_reviews = [w for w in all_reviews if not w in updatestopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean phrases without punctuations and without stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('from its cheesy screenplay', '1'),\n",
       " ('seen lrb eddie rrb', '3'),\n",
       " ('play off each other virtually to a standoff ', '1'),\n",
       " ('colour and', '2'),\n",
       " ('like a soft drink that is been sitting open too long  it is too much syrup and not enough fizz ',\n",
       "  '0'),\n",
       " ('jolts the laughs from the audience ', '3'),\n",
       " ('at least during their s', '2'),\n",
       " ('too campy to work as straight drama', '1'),\n",
       " ('a more credible script ', '3'),\n",
       " ('some other recent efforts', '2')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying only the first 10\n",
    "clean_reviews[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying NLT Word tokenizer to the cleaned reviews**\n",
    "\n",
    "Since we have a clean corpus, NLT Word tokenizer - chosen from earlier analysis - is applied as below to give us clean tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['from', 'its', 'cheesy', 'screenplay'], 1),\n",
       " (['seen', 'lrb', 'eddie', 'rrb'], 3),\n",
       " (['play', 'off', 'each', 'other', 'virtually', 'to', 'a', 'standoff'], 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tokens = word_tokenizer(clean_reviews)\n",
    "\n",
    "# display 3 sentence tokens\n",
    "clean_tokens[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming and Lemmatization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizing using **- WordNetLemmatizer**\n",
    "\n",
    "The function below takes in the cleaned tokens from the previous section and applies NLTK WordNetLemmatizer() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from\n",
      "it\n",
      "cheesy\n",
      "screenplay\n",
      "seen\n",
      "lrb\n",
      "eddie\n",
      "rrb\n",
      "play\n",
      "off\n",
      "each\n",
      "other\n",
      "virtually\n",
      "to\n",
      "a\n",
      "standoff\n"
     ]
    }
   ],
   "source": [
    "def lemmatizer(doc):\n",
    "    new_words = []\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    for word in doc:\n",
    "        for t in word[0]:\n",
    "            lemma = wnl.lemmatize(t)\n",
    "            new_words.append(lemma)\n",
    "    return new_words\n",
    "\n",
    "# show the first 3 sentence tokens\n",
    "lm = lemmatizer(clean_tokens[:3])\n",
    "for item in lm:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming using **-PorterStemmer**\n",
    "\n",
    "The function below takes in the cleaned tokens from the previous section and applies NLTK PorterStemmer() method.\n",
    "\n",
    "It is notewrothy that this stemmer automatically converts every token to lowercase before further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from\n",
      "it\n",
      "cheesi\n",
      "screenplay\n",
      "seen\n",
      "lrb\n",
      "eddi\n",
      "rrb\n",
      "play\n",
      "off\n",
      "each\n",
      "other\n",
      "virtual\n",
      "to\n",
      "a\n",
      "standoff\n"
     ]
    }
   ],
   "source": [
    "def stemmer(doc):\n",
    "    stem = []\n",
    "    porter = nltk.PorterStemmer()\n",
    "    for t in doc:\n",
    "        for item in t[0]:\n",
    "            new_word = porter.stem(item)\n",
    "            stem.append(new_word)\n",
    "        \n",
    "    return stem\n",
    "\n",
    "# show the first 3 sentence tokens\n",
    "stm = stemmer(clean_tokens[:3])\n",
    "for item in stm:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering**\n",
    "\n",
    "Remove single word characters in the reviews since these will not embelish the sentiment detection process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('from its cheesy screenplay', '1'),\n",
       " ('seen lrb eddie rrb', '3'),\n",
       " ('play off each other virtually to a standoff ', '1'),\n",
       " ('colour and', '2'),\n",
       " ('like a soft drink that is been sitting open too long  it is too much syrup and not enough fizz ',\n",
       "  '0'),\n",
       " ('jolts the laughs from the audience ', '3'),\n",
       " ('at least during their s', '2'),\n",
       " ('too campy to work as straight drama', '1'),\n",
       " ('a more credible script ', '3'),\n",
       " ('some other recent efforts', '2')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_char(doc):\n",
    "    word_list=[]\n",
    "    for word in doc:\n",
    "        if (len(word[0]) > 1):\n",
    "            word_list.append((word[0],word[1]))\n",
    "    return word_list\n",
    "\n",
    "cleaner_reviews = remove_char(clean_reviews)\n",
    "cleaner_reviews[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Tokens\n",
    "\n",
    "**Tokens before preprocessing**\n",
    "\n",
    "Applying the NLTK Word Tokenizer method discussed earlier before processing the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'its', 'cheesy', 'screenplay', 'seen', '-LRB-', 'Eddie', '-RRB-', 'play', 'off', 'each', 'other', 'virtually', 'to', 'a', 'stand-off', ',', 'colour', 'and', 'Like', 'a', 'soft', 'drink', 'that', \"'s\", 'been', 'sitting', 'open', 'too', 'long', ':', 'it', \"'s\", 'too', 'much', 'syrup', 'and', 'not', 'enough', 'fizz', '.', 'jolts', 'the', 'laughs', 'from', 'the', 'audience', '--', 'at', 'least', 'during', 'their', \"'70s\", 'Too', 'campy', 'to', 'work', 'as', 'straight', 'drama', 'a', 'more', 'credible', 'script', ',', 'some', 'other', 'recent', 'efforts', 'Opportunists']\n",
      "\n",
      "Total Tokens before processing: : 21361\n"
     ]
    }
   ],
   "source": [
    "# tokens before processing\n",
    "b4t = []\n",
    "before_t = word_tokenizer(reviews)\n",
    "for (word,sentiment) in before_t:\n",
    "    b4t.extend(word)\n",
    "\n",
    "print(b4t[:70])\n",
    "\n",
    "# length of tokens\n",
    "\n",
    "print(\"\\nTotal Tokens before processing: :\", len(b4t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokens after preprocessing**\n",
    "\n",
    "The tokens before and after processing are shown below - with corresponding sizes. Only first 70 tokens are shown and will be used in subsequent analyses to better manage existing memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'its', 'cheesy', 'screenplay', 'seen', 'lrb', 'eddie', 'rrb', 'play', 'off', 'each', 'other', 'virtually', 'to', 'a', 'standoff', 'colour', 'and', 'like', 'a', 'soft', 'drink', 'that', 'is', 'been', 'sitting', 'open', 'too', 'long', 'it', 'is', 'too', 'much', 'syrup', 'and', 'not', 'enough', 'fizz', 'jolts', 'the', 'laughs', 'from', 'the', 'audience', 'at', 'least', 'during', 'their', 's', 'too', 'campy', 'to', 'work', 'as', 'straight', 'drama', 'a', 'more', 'credible', 'script', 'some', 'other', 'recent', 'efforts', 'opportunists', 'rot', 'and', 'hack', 'humility', 'intoxicating']\n",
      "\n",
      "Total Tokens after processing : 19946\n"
     ]
    }
   ],
   "source": [
    "# tokens after processing\n",
    "afterT = []\n",
    "after_t = word_tokenizer(cleaner_reviews)\n",
    "for (word,sentiment) in after_t:\n",
    "    afterT.extend(word)\n",
    "    \n",
    "# only showing the first 70 tokens \n",
    "print(afterT[:70])\n",
    "\n",
    "# length of tokens\n",
    "print(\"\\nTotal Tokens after processing :\", len(afterT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: FEATURE SELECTION ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a Bag of Words Feature**\n",
    "\n",
    "This function creates a bag of words and returns a specified number of most frequent words to be word features.\n",
    "\n",
    "This will be reusable in future experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "def bag_of_words(corpus,wordcount):\n",
    "    wordlist = nltk.FreqDist(corpus)\n",
    "    word_features = [w for (w, c) in wordlist.most_common(wordcount)]\n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Top 10 Unprocessed tokens word features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', ',', 'of', 'and', 'a', 'to', \"'s\", '.', 'in', 'is']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  showing 10 Unprocessed token word features:\n",
    "bag_of_words(b4t,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Top 10 Pre-Processed tokens word features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'a', 'of', 'and', 'to', 'is', 'in', 's', 'that', 'it']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  showing 10 Unprocessed token word features:\n",
    "bag_of_words(afterT,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of words for Bigrams**\n",
    "\n",
    "This function collects all the words in the corpus and select some number (depending on bigramcount passed as argument) of most frequent bigrams. \n",
    "\n",
    "chi-squared measure is used to get bigrams that are informative features.\n",
    "\n",
    "Freq_filter removes words that only occurred with a frequency less than 3. \n",
    "\n",
    "Ngram_filter filters out bigrams in which the first word’s length is less than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "def bag_of_words_biagram(wordlist,bigramcount):\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    finder = BigramCollocationFinder.from_words(wordlist,window_size=3)\n",
    "    finder.apply_ngram_filter(lambda w1, w2: len(w1) < 2)\n",
    "    finder.apply_freq_filter(3)\n",
    "    bigram_features = finder.nbest(bigram_measures.chi_sq, 3000)\n",
    "    return bigram_features[:bigramcount]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Top 10 Unprocessed tokens word features(BIGRAMS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dusty', 'leatherbound'),\n",
       " ('extensive', 'annals'),\n",
       " ('That', 'Want'),\n",
       " ('somber', 'conclusion'),\n",
       " ('urban', 'conflagration'),\n",
       " ('guilty', 'pleasure'),\n",
       " ('encouraging', 'debut'),\n",
       " ('side', 'aplenty'),\n",
       " ('encouraging', 'feature'),\n",
       " ('surprisingly', 'somber')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_biagram(b4t,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Top 10 Pre-processed tokens word features(BIGRAMS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dusty', 'leatherbound'),\n",
       " ('extensive', 'annals'),\n",
       " ('somber', 'conclusion'),\n",
       " ('urban', 'conflagration'),\n",
       " ('road', 'trip'),\n",
       " ('encouraging', 'debut'),\n",
       " ('side', 'aplenty'),\n",
       " ('guilty', 'pleasure'),\n",
       " ('encouraging', 'feature'),\n",
       " ('surprisingly', 'somber')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_biagram(afterT,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the bigram finder must work with words in order, only the uprocessed tokens are used in this experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unigram feature (Baseline feature for comparison):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns a dictionary who’s each element is a word (obtained from bag of words function defined earlier) with a Boolean value indicating whether that word occurred in document or not. The feature label will be ‘has(keyword)’ for each keyword (i.e word) in the bag of words set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_features(doc, word_features):\n",
    "    doc_words = set(doc)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['has(%s)'%word] = (word in doc_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Example, looking at the top 20 most common word features from the unprocessed tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'has(the)': True,\n",
       " 'has(,)': True,\n",
       " 'has(of)': True,\n",
       " 'has(and)': True,\n",
       " 'has(a)': True,\n",
       " 'has(to)': True,\n",
       " \"has('s)\": True,\n",
       " 'has(.)': True,\n",
       " 'has(in)': True,\n",
       " 'has(is)': True,\n",
       " 'has(that)': True,\n",
       " 'has(it)': True,\n",
       " 'has(as)': True,\n",
       " 'has(for)': True,\n",
       " 'has(with)': True,\n",
       " 'has(film)': True,\n",
       " 'has(its)': True,\n",
       " 'has(this)': True,\n",
       " 'has(an)': True,\n",
       " 'has(movie)': True}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word features from unprocessed tokens\n",
    "wf = bag_of_words(b4t,20)\n",
    "\n",
    "# apply\n",
    "unigram_features(b4t,wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bigram feature:**\n",
    "\n",
    "This function takes the list of words in a document as an argument and returns a feature dictionary. It depends on the variables word_features and bigram_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_features(doc,word_features,bigram_features):\n",
    "    document_words = set(doc)\n",
    "    document_bigrams = nltk.bigrams(doc)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['has(%s)' % word] = (word in document_words)\n",
    "    for bigram in bigram_features:\n",
    "        features['bigram(%s %s)' % bigram] = (bigram in document_bigrams)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Bigramsets_without_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'has(the)': True,\n",
       " 'has(,)': True,\n",
       " 'has(of)': True,\n",
       " 'has(and)': True,\n",
       " 'has(a)': True,\n",
       " 'has(to)': True,\n",
       " \"has('s)\": True,\n",
       " 'has(.)': True,\n",
       " 'has(in)': True,\n",
       " 'has(is)': True,\n",
       " 'has(that)': True,\n",
       " 'has(it)': True,\n",
       " 'has(as)': True,\n",
       " 'has(for)': True,\n",
       " 'has(with)': True,\n",
       " 'has(film)': True,\n",
       " 'has(its)': True,\n",
       " 'has(this)': True,\n",
       " 'has(an)': True,\n",
       " 'has(movie)': True,\n",
       " 'bigram(dusty leatherbound)': False,\n",
       " 'bigram(extensive annals)': False,\n",
       " 'bigram(That Want)': False,\n",
       " 'bigram(somber conclusion)': False,\n",
       " 'bigram(urban conflagration)': False,\n",
       " 'bigram(guilty pleasure)': False,\n",
       " 'bigram(encouraging debut)': False,\n",
       " 'bigram(side aplenty)': False,\n",
       " 'bigram(encouraging feature)': False,\n",
       " 'bigram(surprisingly somber)': False}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf_b = bag_of_words_biagram(b4t,10)\n",
    "\n",
    "bigram_feats = bigram_features(b4t,wf,wf_b)\n",
    "bigram_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building Feature set**\n",
    "\n",
    "Below is the construction of **Unigramsets WITHOUT preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramsets_without_preprocessing = [(unigram_features(d, wf), s) for (d, s) in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigramsets_without_preprocessing -\n",
      "({'has(the)': False, 'has(,)': False, 'has(of)': False, 'has(and)': False, 'has(a)': True, 'has(to)': False, \"has('s)\": False, 'has(.)': False, 'has(in)': False, 'has(is)': False, 'has(that)': False, 'has(it)': False, 'has(as)': False, 'has(for)': False, 'has(with)': False, 'has(film)': False, 'has(its)': False, 'has(this)': False, 'has(an)': False, 'has(movie)': False}, '1')\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigramsets_without_preprocessing -\")\n",
    "print(unigramsets_without_preprocessing[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the construction of **Unigramsets WITH preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigramsets_with_preprocessing -\n",
      "({'has(the)': False, 'has(,)': False, 'has(of)': False, 'has(and)': False, 'has(a)': True, 'has(to)': False, \"has('s)\": False, 'has(.)': False, 'has(in)': False, 'has(is)': False, 'has(that)': False, 'has(it)': False, 'has(as)': False, 'has(for)': False, 'has(with)': False, 'has(film)': False, 'has(its)': False, 'has(this)': False, 'has(an)': False, 'has(movie)': False}, '1')\n"
     ]
    }
   ],
   "source": [
    "unigramsets_with_preprocessing = [(unigram_features(d, wf), s) for (d, s) in cleaner_reviews]\n",
    "print(\"Unigramsets_with_preprocessing -\")\n",
    "print(unigramsets_with_preprocessing[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the construction of **Bigramsets WITHOUT preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigramsets_without_preprocessing -\n",
      "({'has(the)': False, 'has(,)': False, 'has(of)': False, 'has(and)': False, 'has(a)': True, 'has(to)': False, \"has('s)\": False, 'has(.)': False, 'has(in)': False, 'has(is)': False, 'has(that)': False, 'has(it)': False, 'has(as)': False, 'has(for)': False, 'has(with)': False, 'has(film)': False, 'has(its)': False, 'has(this)': False, 'has(an)': False, 'has(movie)': False, 'bigram(dusty leatherbound)': False, 'bigram(extensive annals)': False, 'bigram(That Want)': False, 'bigram(somber conclusion)': False, 'bigram(urban conflagration)': False, 'bigram(guilty pleasure)': False, 'bigram(encouraging debut)': False, 'bigram(side aplenty)': False, 'bigram(encouraging feature)': False, 'bigram(surprisingly somber)': False}, '1')\n"
     ]
    }
   ],
   "source": [
    "bigramsets_without_preprocessing = [(bigram_features(d, wf,wf_b), s) for (d, s) in reviews]\n",
    "print(\"Bigramsets_without_preprocessing -\")\n",
    "print(bigramsets_without_preprocessing[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the construction of **Bigramsets WITH preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigramsets_with_preprocessing -\n",
      "({'has(the)': False, 'has(,)': False, 'has(of)': False, 'has(and)': False, 'has(a)': True, 'has(to)': False, \"has('s)\": False, 'has(.)': False, 'has(in)': False, 'has(is)': False, 'has(that)': False, 'has(it)': False, 'has(as)': False, 'has(for)': False, 'has(with)': False, 'has(film)': False, 'has(its)': False, 'has(this)': False, 'has(an)': False, 'has(movie)': False, 'bigram(dusty leatherbound)': False, 'bigram(extensive annals)': False, 'bigram(That Want)': False, 'bigram(somber conclusion)': False, 'bigram(urban conflagration)': False, 'bigram(guilty pleasure)': False, 'bigram(encouraging debut)': False, 'bigram(side aplenty)': False, 'bigram(encouraging feature)': False, 'bigram(surprisingly somber)': False}, '1')\n"
     ]
    }
   ],
   "source": [
    "print(\"Bigramsets_with_preprocessing -\")\n",
    "bigramsets_with_preprocessing = [(bigram_features(d, wf,wf_b), s) for (d, s) in cleaner_reviews]\n",
    "print(bigramsets_with_preprocessing[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Features###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section includes externally sourced negative word dictionary and also the processed version negative words from from prior cleaning. Also included is the processing for whitespaces in some negative words from the initial corpus such as \"can't\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = ['abysmal','adverse','alarming','angry','annoy','anxious','apathy','appalling','atrocious','awful',\n",
    "'bad','banal','barbed','belligerent','bemoan','beneath','boring','broken',\n",
    "'callous','ca n\\'t','clumsy','coarse','cold','cold-hearted','collapse','confused','contradictory','contrary','corrosive','corrupt','crazy','creepy','criminal','cruel','cry','cutting','dead','decaying','damage','damaging','dastardly','deplorable','depressed','deprived','deformed''deny','despicable','detrimental','dirty','disease','disgusting','disheveled','dishonest','dishonorable','dismal','distress','do n\\'t','dreadful','dreary', 'enraged','eroding','evil','fail','faulty','fear','feeble','fight','filthy','foul','frighten','frightful',\n",
    "'gawky','ghastly','grave','greed','grim','grimace','gross','grotesque','gruesome','guilty',\n",
    "'haggard','hard','hard-hearted','harmful','hate','hideous','horrendous','horrible','hostile','hurt','hurtful',\n",
    "'icky','ignore','ignorant','ill','immature','imperfect','impossible','inane','inelegant','infernal','injure','injurious','insane','insidious','insipid',\n",
    "'jealous','junky','lose','lousy','lumpy','malicious','mean','menacing','messy','misshapen','missing','misunderstood','moan','moldy','monstrous',\n",
    "'naive','nasty','naughty','negate','negative','never','no','nobody','nondescript','nonsense','noxious',\n",
    "'objectionable','odious','offensive','old','oppressive',\n",
    "'pain','perturb','pessimistic','petty','plain','poisonous','poor','prejudice','questionable','quirky','quit',\n",
    "'reject','renege','repellant','reptilian','repulsive','repugnant','revenge','revolting','rocky','rotten','rude','ruthless',\n",
    "'sad','savage','scare','scary','scream','severe','shoddy','shocking','sick',\n",
    "'sickening','sinister','slimy','smelly','sobbing','sorry','spiteful','sticky','stinky','stormy','stressful','stuck','stupid','substandard','suspect','suspicious',\n",
    "'tense','terrible','terrifying','threatening',\n",
    "'ugly','undermine','unfair','unfavorable','unhappy','unhealthy','unjust','unlucky','unpleasant','upset','unsatisfactory',\n",
    "'unsightly','untoward','unwanted','unwelcome','unwholesome','unwieldy','unwise','upset','vice','vicious','vile','villainous','vindictive',\n",
    "'wary','weary','wicked','woeful','worthless','wound','yell','yucky',\n",
    "'are n\\'t','cannot','ca n\\'t','could n\\'t','did n\\'t','does n\\'t','do n\\'t','had n\\'t','has n\\'t','have n\\'t','is n\\'t','must n\\'t','sha n\\'t','should n\\'t','was n\\'t','were n\\'t','would n\\'t',\n",
    "'no', 'not', 'never', 'none', 'nowhere', 'nothing', 'noone', 'rather', 'hardly', 'scarcely', 'rarely', 'seldom', 'neither', 'nor']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will pre-process above mentioned negative words dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negativewordproc(negativewords):\n",
    "    nwords = []\n",
    "    nwords = cleanextend(negativewords)\n",
    "    nwords = lemmatizer(nwords)\n",
    "    nwords = stemmer(nwords)\n",
    "    return nwords\n",
    "\n",
    "processnwords = negativewordproc(negative_words)\n",
    "negative_words = negative_words + processnwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I look for negation words and negate the word following the negation word. I will go through the document words in order adding the word features, but if the word follows a negation words, change the feature to negated word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_features(doc, word_features, negationwords):\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['has({})'.format(word)] = False\n",
    "        features['has(NOT{})'.format(word)] = False\n",
    "    # go through document words in order\n",
    "    for i in range(0, len(doc)):\n",
    "        word = doc[i]\n",
    "        if ((i + 1) < len(doc)) and (word in negationwords):\n",
    "            i += 1\n",
    "            features['has(NOT{})'.format(doc[i])] = (doc[i] in word_features)\n",
    "        else:\n",
    "            if ((i + 3) < len(doc)) and (word.endswith('n') and doc[i+1] == \"'\" and doc[i+2] == 't'):\n",
    "                i += 3\n",
    "                features['has(NOT{})'.format(doc[i])] = (doc[i] in word_features)\n",
    "            else:\n",
    "                features['has({})'.format(word)] = (word in word_features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Negativesets without preprocessing -**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'has(the)': False,\n",
       " 'has(NOTthe)': False,\n",
       " 'has(,)': False,\n",
       " 'has(NOT,)': False,\n",
       " 'has(of)': False,\n",
       " 'has(NOTof)': False,\n",
       " 'has(and)': False,\n",
       " 'has(NOTand)': False,\n",
       " 'has(a)': False,\n",
       " 'has(NOTa)': False,\n",
       " 'has(to)': False,\n",
       " 'has(NOTto)': False,\n",
       " \"has('s)\": False,\n",
       " \"has(NOT's)\": False,\n",
       " 'has(.)': False,\n",
       " 'has(NOT.)': False,\n",
       " 'has(in)': False,\n",
       " 'has(NOTin)': False,\n",
       " 'has(is)': False,\n",
       " 'has(NOTis)': False,\n",
       " 'has(that)': False,\n",
       " 'has(NOTthat)': False,\n",
       " 'has(it)': False,\n",
       " 'has(NOTit)': False,\n",
       " 'has(as)': False,\n",
       " 'has(NOTas)': False,\n",
       " 'has(for)': False,\n",
       " 'has(NOTfor)': False,\n",
       " 'has(with)': False,\n",
       " 'has(NOTwith)': False,\n",
       " 'has(film)': False,\n",
       " 'has(NOTfilm)': False,\n",
       " 'has(its)': True,\n",
       " 'has(NOTits)': False,\n",
       " 'has(this)': False,\n",
       " 'has(NOTthis)': False,\n",
       " 'has(an)': False,\n",
       " 'has(NOTan)': False,\n",
       " 'has(movie)': False,\n",
       " 'has(NOTmovie)': False,\n",
       " 'has(from)': False,\n",
       " 'has(cheesy)': False,\n",
       " 'has(screenplay)': False,\n",
       " 'has(seen)': False}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing negative features without preprocessing\n",
    "negative_features(b4t[:5],wf,negative_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  STEP 4: EXPERIMENTS\n",
    "\n",
    "### 1. POS Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below runs the default POS tagger (Stanford tagger) on a given document and counts 4 types of pos tags to use as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def POS_features(doc, word_features):\n",
    "    document_words = set(doc)\n",
    "    tagged_words = nltk.pos_tag(doc)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    numNoun = 0\n",
    "    numVerb = 0\n",
    "    numAdj = 0\n",
    "    numAdverb = 0\n",
    "    for (word, tag) in tagged_words:\n",
    "        if tag.startswith('N'): numNoun += 1\n",
    "        if tag.startswith('V'): numVerb += 1\n",
    "        if tag.startswith('J'): numAdj += 1\n",
    "        if tag.startswith('R'): numAdverb += 1\n",
    "    features['nouns'] = numNoun\n",
    "    features['verbs'] = numVerb\n",
    "    features['adjectives'] = numAdj\n",
    "    features['adverbs'] = numAdverb\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- POS Sets without preprocessing**\n",
    "Calling the function on tokens before processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains(the)': True,\n",
       " 'contains(,)': True,\n",
       " 'contains(of)': True,\n",
       " 'contains(and)': True,\n",
       " 'contains(a)': True,\n",
       " 'contains(to)': True,\n",
       " \"contains('s)\": True,\n",
       " 'contains(.)': True,\n",
       " 'contains(in)': True,\n",
       " 'contains(is)': True,\n",
       " 'contains(that)': True,\n",
       " 'contains(it)': True,\n",
       " 'contains(as)': True,\n",
       " 'contains(for)': True,\n",
       " 'contains(with)': True,\n",
       " 'contains(film)': True,\n",
       " 'contains(its)': True,\n",
       " 'contains(this)': True,\n",
       " 'contains(an)': True,\n",
       " 'contains(movie)': True,\n",
       " 'nouns': 5995,\n",
       " 'verbs': 2750,\n",
       " 'adjectives': 2606,\n",
       " 'adverbs': 1305}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word features from unprocessed tokens\n",
    "# wf = bag_of_words(b4t,20)\n",
    "# where b4t = word tokens before processing\n",
    "\n",
    "# wf is the wordfeatures built earlier before tokenization\n",
    "# showing only first 20 tokens\n",
    "\n",
    "\n",
    "POS_features(b4t, wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- POS Sets with preprocessing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains(the)': True,\n",
       " 'contains(a)': True,\n",
       " 'contains(of)': True,\n",
       " 'contains(and)': True,\n",
       " 'contains(to)': True,\n",
       " 'contains(is)': True,\n",
       " 'contains(in)': True,\n",
       " 'contains(s)': True,\n",
       " 'contains(that)': True,\n",
       " 'contains(it)': True,\n",
       " 'contains(as)': True,\n",
       " 'contains(not)': True,\n",
       " 'contains(for)': True,\n",
       " 'contains(with)': True,\n",
       " 'contains(film)': True,\n",
       " 'contains(its)': True,\n",
       " 'contains(this)': True,\n",
       " 'contains(an)': True,\n",
       " 'contains(movie)': True,\n",
       " 'contains(be)': True,\n",
       " 'nouns': 5714,\n",
       " 'verbs': 3065,\n",
       " 'adjectives': 2732,\n",
       " 'adverbs': 1352}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word features after processing\n",
    "wf_after = bag_of_words(afterT,20)\n",
    "\n",
    "#apply\n",
    "POS_features(afterT, wf_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sentiment Lexicon(Subjectivity) feature:###\n",
    "\n",
    "In order to use this function, we will define one additional function that reads subjectivity words from the subjectivity lexicon file and returns dictionary, where each word is mapped to a list containing the strength and polarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is not imported from sentiment_read_Subjectivity.py as this function is not similar to sentiment_read_Subjectivity.py. This function is modified to include pre-processed version of all words in SL for our pre-processed tokens.\n",
    "\n",
    "In order to pre-process individual words in SL dictionary, I have defined another function. This function takes word and returns stemmed and lemmatized version of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordproc(word):\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    porter = nltk.PorterStemmer()\n",
    "    nwords = wnl.lemmatize(word)\n",
    "    nwords = porter.stem(nwords)\n",
    "    return nwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature function will calculate word counts of subjectivity words. Negative feature will have number of weakly negative words + 2 * number of strongly negative words. Same way it will count for positive features. It will not count neutral words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_SL_path = \"C:/Academics/Natural Language Processing/Final Project/FinalProjectData/FinalProjectData/kagglemoviereviews/SentimentLexicons/subjclueslen1-HLTEMNLP05.tff\"\n",
    "    \n",
    "def SL_features(doc, word_features, path):\n",
    "    # this is the path where the subjectivity doc is located.\n",
    "    # the following lines connects to the file and reads the subjectivity \n",
    "    flexicon = open(path, 'r')\n",
    "    sldict = { }\n",
    "    for line in flexicon:\n",
    "        fields = line.split() # split on whitespace\n",
    "        # split each field on the '=' and keep the second part as the value\n",
    "        strength = fields[0].split(\"=\")[1]\n",
    "        word = fields[2].split(\"=\")[1]\n",
    "        posTag = fields[3].split(\"=\")[1]\n",
    "        stemmed = fields[4].split(\"=\")[1]\n",
    "        polarity = fields[5].split(\"=\")[1]\n",
    "        if (stemmed == 'y'):\n",
    "            isStemmed = True\n",
    "        else:\n",
    "            isStemmed = False\n",
    "        # put a dictionary entry with the word as the keyword\n",
    "        # and a list of the other values\n",
    "        procword = wordproc(word)\n",
    "        sldict[procword] = [strength, posTag, isStemmed, polarity]\n",
    "        sldict[word] = [strength, posTag, isStemmed, polarity]\n",
    "\n",
    "#def SL_features(doc, word_features):   \n",
    "    # the following lines processes and counts positive and negative words\n",
    "    document_words = set(doc)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "        # count variables for the 4 classes of subjectivity\n",
    "        weakPos = 0\n",
    "        strongPos = 0\n",
    "        weakNeg = 0\n",
    "        strongNeg = 0\n",
    "    for word in document_words:\n",
    "        if word in sldict:\n",
    "            strength, posTag, isStemmed, polarity = sldict[word]\n",
    "        if strength == 'weaksubj' and polarity == 'positive':\n",
    "            weakPos += 1\n",
    "        if strength == 'strongsubj' and polarity == 'positive':\n",
    "            strongPos += 1\n",
    "        if strength == 'weaksubj' and polarity == 'negative':\n",
    "            weakNeg += 1\n",
    "        if strength == 'strongsubj' and polarity == 'negative':\n",
    "            strongNeg += 1\n",
    "        features['positivecount'] = weakPos + (2 * strongPos)\n",
    "        features['negativecount'] = weakNeg + (2 * strongNeg)\n",
    "    \n",
    "    if 'positivecount' not in features:\n",
    "        features['positivecount']=0\n",
    "    if 'negativecount' not in features:\n",
    "        features['negativecount']=0\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subjectivitysets without preprocessing -**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains(the)': True,\n",
       " 'contains(,)': True,\n",
       " 'contains(of)': True,\n",
       " 'contains(and)': True,\n",
       " 'contains(a)': True,\n",
       " 'contains(to)': True,\n",
       " \"contains('s)\": True,\n",
       " 'contains(.)': True,\n",
       " 'contains(in)': True,\n",
       " 'contains(is)': True,\n",
       " 'contains(that)': True,\n",
       " 'contains(it)': True,\n",
       " 'contains(as)': True,\n",
       " 'contains(for)': True,\n",
       " 'contains(with)': True,\n",
       " 'contains(film)': True,\n",
       " 'contains(its)': True,\n",
       " 'contains(this)': True,\n",
       " 'contains(an)': True,\n",
       " 'contains(movie)': True,\n",
       " 'positivecount': 3909,\n",
       " 'negativecount': 4385}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SL_features(b4t, wf, the_SL_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subjectivitysets with preprocessing -**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains(the)': True,\n",
       " 'contains(,)': False,\n",
       " 'contains(of)': True,\n",
       " 'contains(and)': True,\n",
       " 'contains(a)': True,\n",
       " 'contains(to)': True,\n",
       " \"contains('s)\": False,\n",
       " 'contains(.)': False,\n",
       " 'contains(in)': True,\n",
       " 'contains(is)': True,\n",
       " 'contains(that)': True,\n",
       " 'contains(it)': True,\n",
       " 'contains(as)': True,\n",
       " 'contains(for)': True,\n",
       " 'contains(with)': True,\n",
       " 'contains(film)': True,\n",
       " 'contains(its)': True,\n",
       " 'contains(this)': True,\n",
       " 'contains(an)': True,\n",
       " 'contains(movie)': True,\n",
       " 'positivecount': 3618,\n",
       " 'negativecount': 4245}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SL_features(afterT, wf, the_SL_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note- Based on a study, more past tense verbs mean negative sentiment and more superlative adverb, means positive sentiment so counting POS will also help in sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LIWC Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have added pre-processed version of positive words and negative words to their respective dictionary that I got by reading LIWC sentiment lexicon file. For this I have reused function defined for pre-processing of negative words dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentiment_read_LIWC_pos_neg_words\n",
    "poslist,neglist = sentiment_read_LIWC_pos_neg_words.read_words()\n",
    "poslist = poslist+negativewordproc(poslist)\n",
    "neglist = neglist+negativewordproc(neglist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have defined another function that will calculate word counts of positive and negative words just like we did subjectivity count earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liwc_features(doc, word_features,poslist,neglist):\n",
    "    doc_words = set(doc)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in doc_words)\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for word in doc_words:\n",
    "        if sentiment_read_LIWC_pos_neg_words.isPresent(word,poslist):\n",
    "            pos += 1\n",
    "        if sentiment_read_LIWC_pos_neg_words.isPresent(word,neglist):\n",
    "            neg += 1\n",
    "        features['positivecount'] = pos\n",
    "        features['negativecount'] = neg\n",
    "        if 'positivecount' not in features:\n",
    "            features['positivecount']=0\n",
    "        if 'negativecount' not in features:\n",
    "            features['negativecount']=0\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Liwcsets without preprocessing -**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains(the)': True,\n",
       " 'contains(,)': True,\n",
       " 'contains(of)': True,\n",
       " 'contains(and)': True,\n",
       " 'contains(a)': True,\n",
       " 'contains(to)': True,\n",
       " \"contains('s)\": True,\n",
       " 'contains(.)': True,\n",
       " 'contains(in)': True,\n",
       " 'contains(is)': True,\n",
       " 'contains(that)': True,\n",
       " 'contains(it)': True,\n",
       " 'contains(as)': True,\n",
       " 'contains(for)': True,\n",
       " 'contains(with)': True,\n",
       " 'contains(film)': True,\n",
       " 'contains(its)': True,\n",
       " 'contains(this)': True,\n",
       " 'contains(an)': True,\n",
       " 'contains(movie)': True,\n",
       " 'positivecount': 351,\n",
       " 'negativecount': 314}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc_features(b4t, wf,poslist,neglist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Liwcsets with preprocessing -**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains(the)': True,\n",
       " 'contains(,)': False,\n",
       " 'contains(of)': True,\n",
       " 'contains(and)': True,\n",
       " 'contains(a)': True,\n",
       " 'contains(to)': True,\n",
       " \"contains('s)\": False,\n",
       " 'contains(.)': False,\n",
       " 'contains(in)': True,\n",
       " 'contains(is)': True,\n",
       " 'contains(that)': True,\n",
       " 'contains(it)': True,\n",
       " 'contains(as)': True,\n",
       " 'contains(for)': True,\n",
       " 'contains(with)': True,\n",
       " 'contains(film)': True,\n",
       " 'contains(its)': True,\n",
       " 'contains(this)': True,\n",
       " 'contains(an)': True,\n",
       " 'contains(movie)': True,\n",
       " 'positivecount': 367,\n",
       " 'negativecount': 338}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc_features(afterT, wf,poslist,neglist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5: CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Employing a Naïve Bayes classifier\n",
    "\n",
    "Next,the feature extractor is used to process the names data, and divide the resulting list of feature sets into a training set and a test set.\n",
    "\n",
    "Naïve Bayes classifier is used to train and test data with 25% as test set initially.\n",
    "\n",
    "The training set is used to train a new \"naive Bayes\" classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the classifier is examined to determine which features it found most effective for distinguishing the reviews along with a confusion matrix, and summary scores (Accuracy, Recall, F-measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import nltk.metrics\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from nltk.metrics import scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_naive_bayes(featuresets,percent):\n",
    "    \n",
    "    # get training and test ratios\n",
    "    training_size = int(percent*len(featuresets))\n",
    "    train_set, test_set = featuresets[training_size:], featuresets[:training_size]\n",
    "    \n",
    "    # train classifer on training set\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    refsets = collections.defaultdict(set)\n",
    "    testsets = collections.defaultdict(set)\n",
    "    \n",
    "    # builds for confusion matrix\n",
    "    reflist = []\n",
    "    testlist = []\n",
    "    for (features, label) in test_set:\n",
    "        reflist.append(label)\n",
    "        testlist.append(classifier.classify(features))\n",
    "    \n",
    "    for i, (feats, label) in enumerate(test_set):\n",
    "        refsets[label].add(i)\n",
    "        observed = classifier.classify(feats)\n",
    "        testsets[observed].add(i)\n",
    "    cm = ConfusionMatrix(reflist, testlist)\n",
    "    \n",
    "    print(\"Naive Bayes Classifier \")\n",
    "    \n",
    "    ############INFORMATIVE FEATURES#################33\n",
    "    print(\"Showing most informative features:\")\n",
    "    print(classifier.show_most_informative_features(10))\n",
    "    \n",
    "    ############CONFUSION MATRIX#################33\n",
    "    print(\"Confusion matrix:\")\n",
    "    #print(cm)\n",
    "    print(cm.pretty_format(sort_by_count=True, show_percents=True))\n",
    "    \n",
    "    #############ACURACY######################3\n",
    "    print(\"Accuracy : \",nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "    \n",
    "    # sets needed for subsequent measures\n",
    "    reference_set = set(refsets)\n",
    "    test_set = set(testlist)\n",
    "   \n",
    "    ############PRECISION####################\n",
    "    print(\"Precision:\", nltk.scores.precision(reference_set, test_set))\n",
    "    \n",
    "    ###########RECALL##################\n",
    "    print(\"Recall:\", nltk.scores.recall(reference_set, test_set))\n",
    "    \n",
    "    ###############F-MEASURE###################\n",
    "    print(\"F-measure:\", nltk.scores.f_measure(reference_set, test_set))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification of UNIGRAM sets WITHOUT preprocessing: \n",
    "Accuracy, Most Informative Features, Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier \n",
      "Showing most informative features:\n",
      "Most Informative Features\n",
      "                  has(.) = True                0 : 2      =      5.4 : 1.0\n",
      "                  has(a) = False               2 : 0      =      3.4 : 1.0\n",
      "                  has(,) = True                4 : 2      =      3.0 : 1.0\n",
      "                  has(.) = False               2 : 0      =      1.4 : 1.0\n",
      "                  has(,) = False               2 : 4      =      1.3 : 1.0\n",
      "                  has(a) = True                0 : 2      =      1.2 : 1.0\n",
      "               has(this) = False               4 : 2      =      1.0 : 1.0\n",
      "                has(for) = False               4 : 2      =      1.0 : 1.0\n",
      "                has(its) = False               4 : 2      =      1.0 : 1.0\n",
      "                 has(of) = False               4 : 2      =      1.0 : 1.0\n",
      "None\n",
      "Confusion matrix:\n",
      "  |      2      3      1      4      0 |\n",
      "--+------------------------------------+\n",
      "2 | <48.7%>  0.7%      .      .      . |\n",
      "3 |  20.7%  <0.7%>     .      .      . |\n",
      "1 |  19.5%   0.8%     <.>     .      . |\n",
      "4 |   4.8%   1.2%      .     <.>     . |\n",
      "0 |   2.7%   0.4%      .      .     <.>|\n",
      "--+------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy :  0.49333333333333335\n",
      "Precision: 1.0\n",
      "Recall: 0.4\n",
      "F-measure: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "nltk_naive_bayes(unigramsets_without_preprocessing, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, the classifier has 0.5 accuracy while a review that has the word \"but\" has equal likelihood to be either positive or slightly negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification of UNIGRAM sets WITH preprocessing: \n",
    "Accuracy, Most Informative Features and Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier \n",
      "Showing most informative features:\n",
      "Most Informative Features\n",
      "                  has(a) = False               2 : 0      =      3.2 : 1.0\n",
      "                  has(a) = True                0 : 2      =      1.2 : 1.0\n",
      "               has(this) = False               0 : 4      =      1.0 : 1.0\n",
      "                has(for) = False               0 : 4      =      1.0 : 1.0\n",
      "                has(its) = False               0 : 4      =      1.0 : 1.0\n",
      "                 has(of) = False               0 : 4      =      1.0 : 1.0\n",
      "                 has('s) = False               0 : 4      =      1.0 : 1.0\n",
      "               has(with) = False               0 : 4      =      1.0 : 1.0\n",
      "                 has(is) = False               0 : 4      =      1.0 : 1.0\n",
      "                has(the) = False               0 : 4      =      1.0 : 1.0\n",
      "None\n",
      "Confusion matrix:\n",
      "  |      2      3      1      4      0 |\n",
      "--+------------------------------------+\n",
      "2 | <49.3%>     .      .      .      . |\n",
      "3 |  21.4%     <.>     .      .      . |\n",
      "1 |  20.3%      .     <.>     .      . |\n",
      "4 |   5.9%      .      .     <.>     . |\n",
      "0 |   3.1%      .      .      .     <.>|\n",
      "--+------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Accuracy :  0.49331550802139035\n",
      "Precision: 1.0\n",
      "Recall: 0.2\n",
      "F-measure: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "nltk_naive_bayes(unigramsets_with_preprocessing, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, the classifier has 0.5 accuracy while a review that has the word \"but\" has equal likelihood to be either positive or slightly negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using different classifiers within the Sci-Kit Learn ecosystem to compare with baseline NLTK Naive Bayes Classifiers\n",
    "\n",
    "Below, I call different classifiers within the Sklearn cluster then print their performance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def sklearn(featuresets,percent):\n",
    "    training_size = int(percent*len(featuresets))\n",
    "    train_set, test_set = featuresets[training_size:], featuresets[:training_size]\n",
    "     \n",
    "    classifier1 = SklearnClassifier(MultinomialNB())\n",
    "    classifier1.train(train_set)\n",
    "    print(\"ScikitLearn Classifier-MultinomialNB\")\n",
    "    print(\"Accuracy : \",nltk.classify.accuracy(classifier1, test_set))\n",
    "    print(\" \")\n",
    "    \n",
    "    classifier2 = SklearnClassifier(BernoulliNB())\n",
    "    classifier2.train(train_set)\n",
    "    print(\"ScikitLearn Classifier-BernoulliNB\")\n",
    "    print(\"Accuracy : \",nltk.classify.accuracy(classifier2, test_set))\n",
    "    print(\" \")\n",
    "    classifier3 = SklearnClassifier(DecisionTreeClassifier())\n",
    "    classifier3.train(train_set)\n",
    "    print(\"ScikitLearn Classifier-Decision Tree\")\n",
    "    print(\"Accuracy : \",nltk.classify.accuracy(classifier3, test_set))\n",
    "    print(\" \")\n",
    "    classifier4 = SklearnClassifier(LogisticRegression())\n",
    "    classifier4.train(train_set)\n",
    "    print(\"ScikitLearn Classifier-LogisticRegression\")\n",
    "    print(\"Accuracy : \",nltk.classify.accuracy(classifier4, test_set))\n",
    "    print(\" \")\n",
    "    classifier5 = SklearnClassifier(SGDClassifier())\n",
    "    classifier5.train(train_set)\n",
    "    print(\"ScikitLearn Classifier-SGDCClassifier\")\n",
    "    print(\"Accuracy : \",nltk.classify.accuracy(classifier5, test_set))\n",
    "    print(\" \")\n",
    "    classifier6 = SklearnClassifier(SVC())\n",
    "    classifier6.train(train_set)\n",
    "    print(\"ScikitLearn Classifier-SVC\")\n",
    "    print(\"Accuracy : \",nltk.classify.accuracy(classifier6, test_set))\n",
    "    print(\" \")\n",
    "    classifier7 = SklearnClassifier(LinearSVC()) \n",
    "    classifier7.train(train_set)\n",
    "    print(\"ScikitLearn Classifier-LinearSVC\")\n",
    "    print(\"Accuracy : \",nltk.classify.accuracy(classifier7, test_set))\n",
    "    print(\" \")\n",
    "    classifier8 = SklearnClassifier(NuSVC(nu=0.09))\n",
    "    classifier8.train(train_set)\n",
    "    print(\"ScikitLearn Classifier-NuSVC\")\n",
    "    print(\"Accuracy : \",nltk.classify.accuracy(classifier8, test_set))\n",
    "    print(\" \")\n",
    "    classifier9 = SklearnClassifier(RandomForestClassifier())\n",
    "    classifier9.train(train_set)\n",
    "    print(\"ScikitLearn Classifier-RandomForest\")\n",
    "    print(\"Accuracy : \",nltk.classify.accuracy(classifier9, test_set))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scores from different classifiers - WITHOUT PREPROCESSING:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScikitLearn Classifier-MultinomialNB\n",
      "Accuracy :  0.49331550802139035\n",
      " \n",
      "ScikitLearn Classifier-BernoulliNB\n",
      "Accuracy :  0.49331550802139035\n",
      " \n",
      "ScikitLearn Classifier-Decision Tree\n",
      "Accuracy :  0.49331550802139035\n",
      " \n",
      "ScikitLearn Classifier-LogisticRegression\n",
      "Accuracy :  0.49331550802139035\n",
      " \n",
      "ScikitLearn Classifier-SGDCClassifier\n",
      "Accuracy :  0.49331550802139035\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\StephenOmondi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\StephenOmondi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\StephenOmondi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScikitLearn Classifier-SVC\n",
      "Accuracy :  0.49331550802139035\n",
      " \n",
      "ScikitLearn Classifier-LinearSVC\n",
      "Accuracy :  0.49331550802139035\n",
      " \n",
      "ScikitLearn Classifier-NuSVC\n",
      "Accuracy :  0.058823529411764705\n",
      " \n",
      "ScikitLearn Classifier-RandomForest\n",
      "Accuracy :  0.49331550802139035\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\StephenOmondi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\StephenOmondi\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sklearn(unigramsets_with_preprocessing,0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scores from different classifiers - WITH PREPROCESSING:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScikitLearn Classifier-MultinomialNB\n",
      "Accuracy :  0.49331550802139035\n",
      " \n",
      "ScikitLearn Classifier-BernoulliNB\n",
      "Accuracy :  0.49331550802139035\n",
      " \n",
      "ScikitLearn Classifier-Decision Tree\n",
      "Accuracy :  0.49331550802139035\n",
      " \n",
      "ScikitLearn Classifier-LogisticRegression\n",
      "Accuracy :  0.49331550802139035\n",
      " \n",
      "ScikitLearn Classifier-SGDCClassifier\n",
      "Accuracy :  0.49331550802139035\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\StephenOmondi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\StephenOmondi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\StephenOmondi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScikitLearn Classifier-SVC\n",
      "Accuracy :  0.49331550802139035\n",
      " \n",
      "ScikitLearn Classifier-LinearSVC\n",
      "Accuracy :  0.49331550802139035\n",
      " \n",
      "ScikitLearn Classifier-NuSVC\n",
      "Accuracy :  0.058823529411764705\n",
      " \n",
      "ScikitLearn Classifier-RandomForest\n",
      "Accuracy :  0.49331550802139035\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\StephenOmondi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\StephenOmondi\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sklearn(unigramsets_with_preprocessing,0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CROSS-VALIDATION###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tri-fold Fold Performances of Naive Bayes classifier against feature sets -**\n",
    "\n",
    "Below, I undertake cross validation using three fold method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Starting with unigrams Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I create a method that evaluates performance measures, which I then call in the subsequent classification method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_measures(reflist, testlist, label_list):\n",
    "    #initialize sets\n",
    "    # for each label in the label list, make a set of the indexes of the ref and test items\n",
    "    # store them in sets for each label, stored in dictionaries\n",
    "    # first create dictionaries\n",
    "    ref_sets = {}\n",
    "    test_sets = {}\n",
    "    # create empty sets for each label\n",
    "    for lab in label_list:\n",
    "        ref_sets[lab] = set()\n",
    "        test_sets[lab] = set()\n",
    "   \n",
    "    # get gold labels\n",
    "    for j, label in enumerate(reflist):\n",
    "        ref_sets[label].add(j)\n",
    "    \n",
    "    # get predicted labels\n",
    "    for k, label in enumerate(testlist):\n",
    "        test_sets[label].add(k)\n",
    "    \n",
    "    # lists to return precision and recall for all labels\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    \n",
    "    #compute precision and recall for all labels using the NLTK functions\n",
    "    for lab in label_list:\n",
    "        precision_list.append ( precision(ref_sets[lab], test_sets[lab]))\n",
    "        recall_list.append ( recall(ref_sets[lab], test_sets[lab]))\n",
    "    return (precision_list, recall_list)\n",
    "\n",
    "\n",
    "def naive_bayes(num_folds, featuresets, label_list):\n",
    "    subset_size = int(len(featuresets)/num_folds)\n",
    "    # overall gold labels for each instance (reference) and predicted labels (test)\n",
    "    reflist = []\n",
    "    testlist = []\n",
    "    accuracy_list = []\n",
    "    print(\"Naive Bayes Classifier\")\n",
    "    # iterate over the folds\n",
    "    for i in range(num_folds):\n",
    "        print('Start Fold', i)\n",
    "        test_this_round = featuresets[i*subset_size:][:subset_size]\n",
    "        train_this_round = featuresets[:i*subset_size]+featuresets[(i+1)*subset_size:]\n",
    "        # train using train_this_round\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_this_round)\n",
    "        # evaluate against test_this_round and save accuracy\n",
    "        accuracy_this_round = nltk.classify.accuracy(classifier, test_this_round)\n",
    "        print(i, accuracy_this_round)\n",
    "        accuracy_list.append(accuracy_this_round)\n",
    "    # add the gold labels and predicted labels for this round to the overall lists\n",
    "    for (features, label) in test_this_round:\n",
    "        reflist.append(label)\n",
    "        testlist.append(classifier.classify(features))\n",
    "    print('Done with cross-validation')\n",
    "    # call the evaluation measures function\n",
    "    print('mean accuracy-', sum(accuracy_list) / num_folds)\n",
    "    (precision_list, recall_list) = eval_measures(reflist, testlist, label_list)\n",
    "    #print_evaluation (precision_list, recall_list, label_list)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation of unigram sets with preprocessing, using 10 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier\n",
      "Start Fold 0\n",
      "0 0.47491638795986624\n",
      "Start Fold 1\n",
      "1 0.48494983277591974\n",
      "Start Fold 2\n",
      "2 0.5284280936454849\n",
      "Start Fold 3\n",
      "3 0.5484949832775919\n",
      "Start Fold 4\n",
      "4 0.5217391304347826\n",
      "Start Fold 5\n",
      "5 0.47491638795986624\n",
      "Start Fold 6\n",
      "6 0.5150501672240803\n",
      "Start Fold 7\n",
      "7 0.5083612040133779\n",
      "Start Fold 8\n",
      "8 0.5217391304347826\n",
      "Start Fold 9\n",
      "9 0.4916387959866221\n",
      "Done with cross-validation\n",
      "mean accuracy- 0.5070234113712375\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'precision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-442f14f83bd1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnaive_bayes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munigramsets_with_preprocessing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'4'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-64-8b078a87f7dd>\u001b[0m in \u001b[0;36mnaive_bayes\u001b[1;34m(num_folds, featuresets, label_list)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m# call the evaluation measures function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mean accuracy-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mprecision_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_measures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreflist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;31m#print_evaluation (precision_list, recall_list, label_list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-8b078a87f7dd>\u001b[0m in \u001b[0;36meval_measures\u001b[1;34m(reflist, testlist, label_list)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m#compute precision and recall for all labels using the NLTK functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlab\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mprecision_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlab\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlab\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mrecall_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlab\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlab\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprecision_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'precision' is not defined"
     ]
    }
   ],
   "source": [
    "naive_bayes(10, unigramsets_with_preprocessing, ['0','1','2','3','4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation of unigram sets without preprocessing, using 10 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier\n",
      "Start Fold 0\n",
      "0 0.48\n",
      "Start Fold 1\n",
      "1 0.49\n",
      "Start Fold 2\n",
      "2 0.51\n",
      "Start Fold 3\n",
      "3 0.5533333333333333\n",
      "Start Fold 4\n",
      "4 0.51\n",
      "Start Fold 5\n",
      "5 0.47333333333333333\n",
      "Start Fold 6\n",
      "6 0.5033333333333333\n",
      "Start Fold 7\n",
      "7 0.51\n",
      "Start Fold 8\n",
      "8 0.5166666666666667\n",
      "Start Fold 9\n",
      "9 0.5\n",
      "Done with cross-validation\n",
      "mean accuracy- 0.5046666666666666\n",
      " \n"
     ]
    }
   ],
   "source": [
    "naive_bayes(10, unigramsets_without_preprocessing, ['0','1','2','3','4'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
